server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    # Hide Nginx version for security
    server_tokens off;

    # --- SECURITY HEADERS ---
    # Tightened CSP to allow local data and necessary CDNs
    add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' unpkg.com cdnjs.cloudflare.com; style-src 'self' 'unsafe-inline' cdnjs.cloudflare.com fonts.googleapis.com; font-src 'self' fonts.gstatic.com; img-src 'self' data:; connect-src 'self' http://localhost:11434 http://127.0.0.1:11434 http://host.docker.internal:11434;" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-Frame-Options "DENY" always;
    add_header Referrer-Policy "no-referrer" always;
    add_header Permissions-Policy "camera=(), microphone=(), geolocation=()" always;

    location / {
        try_files $uri $uri/ /index.html;
    }

    # --- REAL-TIME STATS FIX ---
    # Prevents the browser from caching hardware monitoring data
    location = /stats.json {
        add_header Cache-Control "no-cache, no-store, must-revalidate";
        add_header Pragma "no-cache";
        add_header Expires 0;
        try_files $uri =404;
    }

    # --- OLLAMA PROXY ---
    location /api/ {
        # Redirects API calls to the Ollama backend
        proxy_pass http://host.docker.internal:11434;
        
        proxy_set_header Host $host;
        proxy_buffering off;         # Crucial for streaming AI responses
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        
        # Extended timeouts for long AI thinking processes
        proxy_connect_timeout 10s;
        proxy_read_timeout 300s;
    }
}
